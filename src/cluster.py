"""

Usage:
    cluster.py --tmf=<TestMentionsFile> --predictions=<TestPredictionsPickle> [--print=readable]
            [--alt=<AverageLinkThresh>]

Options:
    -h --help                               Show this screen.
    --predictions=<TestPredictionsPickle>   Path to matrix prediction file generated by cross_doc_coref
    --print=<PrintFormat>                   readable/conll - print in human readable format or in the conll format [default: readable]
    --alt=<AverageLinkThresh>               The link threshold for the clustering algorithm [default: 0.7]
"""

import logging

import pickle
import os,sys

root_path = os.path.abspath(__file__)
root_path = '/'.join(root_path.split('/')[:-2]) #windows 用\
sys.path.append(root_path)

from docopt import docopt
from collections import defaultdict
from Metric.metric import muc, ceaf, b_cubed, conll_coref_f1

from src.dataobjs.cluster import Clusters
from src.dataobjs.topics import Topics
from src.utils.clustering_utils import agglomerative_clustering
from src.utils.io_utils import write_coref_scorer_results

from src.utils.log_utils import create_logger_with_fh
from datetime import datetime

logger = logging.getLogger(__name__)


def cluster_and_print():
    all_mentions = list()
    logger.info('Running event coref resolution for average_link_thresh=' + str(_average_link_thresh))
    for topic, pred in _predictions:
        logger.info("Evaluating Topic No:" + str(topic.topic_id))
        all_mentions.extend(agglomerative_clustering(pred, topic, _average_link_thresh))
    logger.info("Generating scorer file-" + _scorer_file)
    _print_method(all_mentions, _scorer_file)


""" def print_results(all_mentions, scorer_out_file):
    all_clusters = Clusters.from_mentions_to_predicted_clusters(all_mentions)
    for cluster_id, cluster in all_clusters.items():
        print(cluster[0].coref_chain)
        print(len(cluster))
        if "Singleton" in cluster[0].coref_chain and len(cluster) == 1:#过滤掉了单例样本
            continue

        print('\n\t## Cluster=' + str(cluster_id) + " ##")
        for mention in cluster:
            mentions_dict = dict()
            mentions_dict['id'] = mention.mention_id
            mentions_dict['text'] = mention.tokens_str
            mentions_dict['gold'] = mention.coref_chain

            if mention.tokens_number[0] >= 10 and (mention.tokens_number[-1] + 10) < len(mention.mention_context):
                id_start = mention.tokens_number[0] - 10
                id_end = mention.tokens_number[-1] + 10
            elif mention.tokens_number[0] < 10 and (mention.tokens_number[-1] + 10) < len(mention.mention_context):
                id_start = 0
                id_end = mention.tokens_number[-1] + 10
            elif mention.tokens_number[0] >= 10 and (mention.tokens_number[-1] + 10) >= len(mention.mention_context):
                id_start = mention.tokens_number[0] - 10
                id_end = len(mention.mention_context)
            else:
                id_start = 0
                id_end = len(mention.mention_context)

            before = " ".join(mention.mention_context[id_start:mention.tokens_number[0]])
            after = " ".join(mention.mention_context[mention.tokens_number[-1] + 1:id_end])
            mention_txt = " <" + mention.tokens_str + "> "
            mentions_dict['context'] = before + mention_txt + after

            print('\t\tMentions='+ str(mentions_dict)) """


def print_results(all_mentions, scorer_out_file):
    all_clusters = Clusters.from_mentions_to_predicted_clusters(all_mentions)

    #gold_lable_dict
    gold_lable_dict=defaultdict(list)#每个coref_chain对应的index
    for mention in all_mentions:
        gold_lable_dict[mention.coref_chain].append(mention.mention_index)

    # del_list=[]
    # for coref,value in gold_lable_dict.items():
    #     if len(value)==1:
    #         del_list.append(coref)
    # for i in del_list:del gold_lable_dict[i]
    pred_cluster_list=[]
    for cluster_id, cluster in all_clusters.items():
        if  len(cluster) == 1  and len(gold_lable_dict[cluster[0].coref_chain])==1:#过滤掉了单例样本,gold和预测都是单例样本，去除
            gold_lable_dict.pop(cluster[0].coref_chain)
            # del gold_lable_dict[cluster[0].coref_chain]
            continue
        # if len(cluster)==0:continue
        cluster_list = []#当前聚类的样本
        for mention in cluster:
            cluster_list.append(mention.mention_index)
        pred_cluster_list.append(cluster_list)
    
    gold_cluster_list=list(gold_lable_dict.values())
    # print(f"len(gold):{len(gold_cluster_list)},gold:{gold_cluster_list}")
    # print(f"len(pred):{len(pred_cluster_list )},pred:{pred_cluster_list}")
    metrics_result(pred_cluster_list,gold_cluster_list)

def metrics_result(cluster_pred,cluster_gold):
        muc_metric=muc(cluster_pred,cluster_gold)
        b3_metric=b_cubed(cluster_pred,cluster_gold)
        ceaf_metric=ceaf(cluster_pred,cluster_gold)
        conll_coref_f1_metric=conll_coref_f1(cluster_pred,cluster_gold)
        logger.info(f"P,R,F1\n muc:{muc_metric}\n b3:{b3_metric}\n ceaf:{ceaf_metric}\n conll_f1:{conll_coref_f1_metric}")   

def print_scorer_results(all_mentions, scorer_out_file):
    write_coref_scorer_results(all_mentions, scorer_out_file)


if __name__ == '__main__':

    os.chdir(root_path)

    # logging.basicConfig(level=logging.INFO)

    start_time = datetime.now()
    dt_string = start_time.strftime("%Y-%m-%d_%H-%M")

    
    argv=['--tmf','./datasets/WEC-Eng/final_processed/Test_Event_gold_mentions_validated.json',
          '--predictions','./model/pair_pred_model.pickle','--alt',0.9]
    _arguments = docopt(__doc__, argv=argv, help=True, version=None, options_first=False)
    print(_arguments)
    _mentions_file = _arguments.get("--tmf")
    _predictions_file = _arguments.get("--predictions")
    _average_link_thresh = float(_arguments.get("--alt"))
    _print_method_arg = _arguments.get("--print")
    _scorer_file = _predictions_file + "_" + str(_average_link_thresh)
    _event_topics = Topics()
    _event_topics.create_from_file(_mentions_file, True)
    _predictions = pickle.load(open(_predictions_file, "rb"))#这里会改变工作目录
    os.chdir(root_path)
    
    log_param =  dt_string
    create_logger_with_fh("checkpoints/cluster_"+dt_string+"_lexical_chains")

    if _print_method_arg == "readable":
        _print_method = print_results
    else:
        _print_method = print_scorer_results

    cluster_and_print()
